{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Deh7NK7XXG19"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "import shap\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "# ==== RAG / Chatbot imports ====\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "client = OpenAI()  # uses OPENAI_API_KEY from env / Streamlit secrets\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# BASIC PAGE CONFIG\n",
        "# ---------------------------------------------------\n",
        "st.set_page_config(\n",
        "    page_title=\"Banff Parking â€“ ML & XAI Dashboard\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# LOAD MODELS + DATA (CACHED)\n",
        "# ---------------------------------------------------\n",
        "@st.cache_resource\n",
        "def load_models_and_data():\n",
        "    \"\"\"Load trained models, scaler, feature list, and test data.\"\"\"\n",
        "    reg = joblib.load(\"banff_best_xgb_reg.pkl\")      # XGBoost regressor\n",
        "    cls = joblib.load(\"banff_best_xgb_cls.pkl\")      # XGBoost classifier\n",
        "    scaler = joblib.load(\"banff_scaler.pkl\")         # Scaler used in training\n",
        "    features = joblib.load(\"banff_features.pkl\")     # List of feature names\n",
        "\n",
        "    # Test data for XAI and residual analysis\n",
        "    X_test_scaled = np.load(\"X_test_scaled.npy\")\n",
        "    y_reg_test = np.load(\"y_reg_test.npy\")\n",
        "\n",
        "    return reg, cls, scaler, features, X_test_scaled, y_reg_test\n",
        "\n",
        "\n",
        "best_xgb_reg, best_xgb_cls, scaler, FEATURES, X_test_scaled, y_reg_test = load_models_and_data()\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# RAG: LOAD KNOWLEDGE + BUILD VECTORIZER\n",
        "# ---------------------------------------------------\n",
        "@st.cache_resource\n",
        "def load_rag_knowledge():\n",
        "    \"\"\"\n",
        "    Loads banff_knowledge.txt and builds TF-IDF vectors.\n",
        "    Each non-empty line is treated as a small document.\n",
        "    \"\"\"\n",
        "    knowledge_path = \"banff_knowledge.txt\"\n",
        "\n",
        "    if not os.path.exists(knowledge_path):\n",
        "        docs = [\n",
        "            \"This is Gurleen's Banff parking assistant. The banff_knowledge.txt file is \"\n",
        "            \"missing, so answers are based only on general parking logic.\"\n",
        "        ]\n",
        "    else:\n",
        "        with open(knowledge_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            docs = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    doc_embeddings = vectorizer.fit_transform(docs)\n",
        "\n",
        "    return docs, vectorizer, doc_embeddings\n",
        "\n",
        "\n",
        "def retrieve_context(query, docs, vectorizer, doc_embeddings, k=5):\n",
        "    \"\"\"Returns top-k most relevant lines from the knowledge base.\"\"\"\n",
        "    query_vec = vectorizer.transform([query])\n",
        "    sims = cosine_similarity(query_vec, doc_embeddings).flatten()\n",
        "    top_idx = sims.argsort()[::-1][:k]\n",
        "    selected = [docs[i] for i in top_idx if sims[i] > 0.0]\n",
        "\n",
        "    if not selected:\n",
        "        return \"No strong matches in the knowledge base. Answer based on general parking logic.\"\n",
        "\n",
        "    return \"\\n\".join(selected)\n",
        "\n",
        "\n",
        "def generate_chat_answer(user_question, chat_history):\n",
        "    \"\"\"\n",
        "    Calls OpenAI with retrieved context + short chat history.\n",
        "    If the API fails (e.g., insufficient_quota), fall back to\n",
        "    a simple answer built only from the retrieved context.\n",
        "    \"\"\"\n",
        "    docs, vectorizer, doc_embeddings = load_rag_knowledge()\n",
        "    context = retrieve_context(user_question, docs, vectorizer, doc_embeddings, k=5)\n",
        "\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": (\n",
        "                \"You are a friendly project assistant helping Gurleen explain a Banff \"\n",
        "                \"parking analytics project. Speak clearly and simply, as if you are \"\n",
        "                \"presenting to classmates and instructors who are not data scientists. \"\n",
        "                \"Use the provided 'Context' from the project notes as your main source \"\n",
        "                \"of truth. If the context does not clearly contain the answer, say that \"\n",
        "                \"openly and give a short, reasonable guess based on typical parking \"\n",
        "                \"behaviour.\"\n",
        "            ),\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": f\"Context from project notes:\\n{context}\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # keep last few turns of history\n",
        "    for h in chat_history[-4:]:\n",
        "        messages.append(\n",
        "            {\n",
        "                \"role\": h[\"role\"],\n",
        "                \"content\": h[\"content\"],\n",
        "            }\n",
        "        )\n",
        "\n",
        "    messages.append({\"role\": \"user\", \"content\": user_question})\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4.1-mini\",\n",
        "            messages=messages,\n",
        "            temperature=0.3,\n",
        "        )\n",
        "        return response.choices[0].message.content.strip()\n",
        "    except Exception:\n",
        "        # Friendly fallback when quota is exhausted or API not reachable\n",
        "        return (\n",
        "            \"I couldnâ€™t contact the language-model service right now \"\n",
        "            \"(this usually means the OpenAI API quota or free credits are used up \"\n",
        "            \"for this key).\\n\\n\"\n",
        "            \"Here is the most relevant information I can give based only on \"\n",
        "            \"the project notes:\\n\\n\"\n",
        "            f\"{context}\"\n",
        "        )\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# SIDEBAR NAVIGATION\n",
        "# ---------------------------------------------------\n",
        "st.sidebar.title(\"Banff Parking Dashboard\")\n",
        "st.sidebar.markdown(\n",
        "    \"\"\"\n",
        "    Use this app to:\n",
        "    - Explore hourly parking demand\n",
        "    - Check which lots may be full\n",
        "    - Understand the model using XAI\n",
        "    - Chat with a **parking assistant** using RAG\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "page = st.sidebar.radio(\n",
        "    \"Go to\",\n",
        "    [\n",
        "        \"Overview\",\n",
        "        \"Make Prediction\",\n",
        "        \"Lot Status Overview\",\n",
        "        \"XAI â€“ Explainable AI\",\n",
        "        \"ðŸ’¬ Chat Assistant (RAG)\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# PAGE 1 â€“ OVERVIEW\n",
        "# ---------------------------------------------------\n",
        "if page == \"Overview\":\n",
        "    st.title(\"ðŸš— Banff Parking Demand â€“ Machine Learning Overview\")\n",
        "\n",
        "    col_left, col_right = st.columns([1.4, 1])\n",
        "\n",
        "    with col_left:\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            ### Project Question\n",
        "\n",
        "            **How can Banff use real data to anticipate parking pressure and avoid full lots during the Mayâ€“September tourist season?**\n",
        "\n",
        "            This project combines:\n",
        "\n",
        "            - **Parking management data** â€“ when and where people park\n",
        "            - **Weather data** â€“ temperature, rain, and wind\n",
        "            - **Engineered features** â€“ hour, weekday/weekend, lagged occupancy, rolling averages\n",
        "\n",
        "            A Gradient-boosted tree model (**XGBoost**) predicts:\n",
        "            - Hourly **occupancy level** for each lot\n",
        "            - **Probability that a lot is near full** (> 90% capacity)\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with col_right:\n",
        "        st.markdown(\"### Quick Facts (from engineered data)\")\n",
        "        kpi1, kpi2 = st.columns(2)\n",
        "        with kpi1:\n",
        "            st.metric(\"Tourist season\", \"Mayâ€“September 2025\")\n",
        "        with kpi2:\n",
        "            st.metric(\"Lots modelled\", \"Multiple Banff units\")\n",
        "        kpi3, kpi4 = st.columns(2)\n",
        "        with kpi3:\n",
        "            st.metric(\"Target 1\", \"Hourly occupancy\")\n",
        "        with kpi4:\n",
        "            st.metric(\"Target 2\", \"Full / Not-full\")\n",
        "\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            âœ… Models trained on **historical hourly data**\n",
        "            âœ… Includes **time, weather, and history** features\n",
        "            âœ… Deployed as this **Streamlit decision-support app**\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    st.markdown(\"---\")\n",
        "\n",
        "    st.subheader(\"How to Use This App\")\n",
        "\n",
        "    col1, col2, col3 = st.columns(3)\n",
        "\n",
        "    with col1:\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            **1. Make Prediction**\n",
        "            - Choose a **lot & scenario**\n",
        "            - Adjust **time & weather**\n",
        "            - See predicted occupancy & full-lot risk\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with col2:\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            **2. Lot Status Overview**\n",
        "            - Select a **single hour**\n",
        "            - Compare **all lots**\n",
        "            - Status: ðŸŸ¥ High risk full, ðŸŸ§ Busy, ðŸŸ© Comfortable\n",
        "            - Supports operational decisions & signage\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    with col3:\n",
        "        st.markdown(\n",
        "            \"\"\"\n",
        "            **3. XAI â€“ Explainable AI**\n",
        "            - Global **SHAP** feature importance\n",
        "            - **Partial Dependence Plots** (Hour, Month, Temp)\n",
        "            - **Residual plot** to check model fit\n",
        "            - Helps justify decisions to stakeholders\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "    st.info(\n",
        "        \"Tip: move between pages using the left sidebar. Start with \"\n",
        "        \"**Make Prediction** to see how the model behaves for different scenarios.\"\n",
        "    )\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# PAGE 2 â€“ MAKE PREDICTION (NO FUTURE GRAPH)\n",
        "# ---------------------------------------------------\n",
        "if page == \"Make Prediction\":\n",
        "    st.title(\"ðŸŽ¯ Interactive Parking Demand Prediction\")\n",
        "\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        Use this page to explore *what-if* scenarios for a single Banff parking lot.\n",
        "\n",
        "        1. Select a **parking lot**\n",
        "        2. Choose a **scenario** (or adjust the sliders)\n",
        "        3. See:\n",
        "           - Predicted **occupancy** for the selected hour\n",
        "           - **Probability** the lot is near full\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Find lot indicator features (one-hot encoded units)\n",
        "    lot_features = [f for f in FEATURES if f.startswith(\"Unit_\")]\n",
        "    lot_display_names = [lf.replace(\"Unit_\", \"\").replace(\"_\", \" \") for lf in lot_features]\n",
        "\n",
        "    # Sort lot list alphabetically so numbers appear in order (BANFF02, BANFF03, â€¦)\n",
        "    if lot_features:\n",
        "        lot_pairs = sorted(zip(lot_features, lot_display_names), key=lambda x: x[1])\n",
        "        lot_features, lot_display_names = zip(*lot_pairs)\n",
        "        lot_features = list(lot_features)\n",
        "        lot_display_names = list(lot_display_names)\n",
        "\n",
        "    if not lot_features:\n",
        "        st.warning(\n",
        "            \"No parking-lot indicator features (starting with 'Unit_') were \"\n",
        "            \"found in FEATURES. Lot selection is disabled; generic features only.\"\n",
        "        )\n",
        "\n",
        "    # Scenario presets\n",
        "    scenario_options = {\n",
        "        \"Custom (use sliders below)\": None,\n",
        "        \"Sunny Weekend Midday\": {\"month\": 7, \"dow\": 5, \"hour\": 13,\n",
        "                                 \"max_temp\": 24.0, \"precip\": 0.0, \"gust\": 10.0},\n",
        "        \"Rainy Weekday Afternoon\": {\"month\": 6, \"dow\": 2, \"hour\": 16,\n",
        "                                    \"max_temp\": 15.0, \"precip\": 5.0, \"gust\": 20.0},\n",
        "        \"Cold Morning (Shoulder Season)\": {\"month\": 5, \"dow\": 1, \"hour\": 9,\n",
        "                                           \"max_temp\": 5.0, \"precip\": 0.0, \"gust\": 15.0},\n",
        "        \"Warm Evening (Busy Day)\": {\"month\": 8, \"dow\": 6, \"hour\": 19,\n",
        "                                    \"max_temp\": 22.0, \"precip\": 0.0, \"gust\": 8.0},\n",
        "    }\n",
        "\n",
        "    st.subheader(\"Step 1 â€“ Choose Lot & Scenario\")\n",
        "\n",
        "    col_lot, col_scenario = st.columns([1.2, 1])\n",
        "\n",
        "    with col_lot:\n",
        "        if lot_features:\n",
        "            selected_lot_label = st.selectbox(\n",
        "                \"Select parking lot\",\n",
        "                lot_display_names,\n",
        "                index=0\n",
        "            )\n",
        "            selected_lot_feature = lot_features[lot_display_names.index(selected_lot_label)]\n",
        "        else:\n",
        "            selected_lot_label = None\n",
        "            selected_lot_feature = None\n",
        "\n",
        "    with col_scenario:\n",
        "        selected_scenario = st.selectbox(\n",
        "            \"Scenario\",\n",
        "            list(scenario_options.keys()),\n",
        "            index=1\n",
        "        )\n",
        "\n",
        "    # Default slider values â€“ will be overwritten by scenario if chosen\n",
        "    default_vals = {\"month\": 7, \"dow\": 5, \"hour\": 13,\n",
        "                    \"max_temp\": 22.0, \"precip\": 0.5, \"gust\": 12.0}\n",
        "\n",
        "    if scenario_options[selected_scenario] is not None:\n",
        "        default_vals.update(scenario_options[selected_scenario])\n",
        "\n",
        "    st.subheader(\"Step 2 â€“ Adjust Conditions (if needed)\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        month = st.slider(\"Month (1 = Jan, 12 = Dec)\",\n",
        "                          1, 12, int(default_vals[\"month\"]))\n",
        "        day_of_week = st.slider(\"Day of Week (0 = Monday, 6 = Sunday)\",\n",
        "                                0, 6, int(default_vals[\"dow\"]))\n",
        "        hour = st.slider(\"Hour of Day (0â€“23)\",\n",
        "                         0, 23, int(default_vals[\"hour\"]))\n",
        "\n",
        "    with col2:\n",
        "        max_temp = st.slider(\"Max Temperature (Â°C)\",\n",
        "                             -20.0, 40.0, float(default_vals[\"max_temp\"]))\n",
        "        total_precip = st.slider(\"Total Precipitation (mm)\",\n",
        "                                 0.0, 30.0, float(default_vals[\"precip\"]))\n",
        "        wind_gust = st.slider(\"Speed of Max Gust (km/h)\",\n",
        "                              0.0, 100.0, float(default_vals[\"gust\"]))\n",
        "\n",
        "    is_weekend = 1 if day_of_week in [5, 6] else 0\n",
        "\n",
        "    st.caption(\n",
        "        \"Lag features (previous-hour occupancy, rolling averages) are set automatically \"\n",
        "        \"by the model and are not entered manually here.\"\n",
        "    )\n",
        "\n",
        "    # Build feature dict starting from all zeros\n",
        "    base_input = {f: 0 for f in FEATURES}\n",
        "\n",
        "    # Time & weather\n",
        "    if \"Month\" in base_input:\n",
        "        base_input[\"Month\"] = month\n",
        "    if \"DayOfWeek\" in base_input:\n",
        "        base_input[\"DayOfWeek\"] = day_of_week\n",
        "    if \"Hour\" in base_input:\n",
        "        base_input[\"Hour\"] = hour\n",
        "    if \"IsWeekend\" in base_input:\n",
        "        base_input[\"IsWeekend\"] = is_weekend\n",
        "    if \"Max Temp (Â°C)\" in base_input:\n",
        "        base_input[\"Max Temp (Â°C)\"] = max_temp\n",
        "    if \"Total Precip (mm)\" in base_input:\n",
        "        base_input[\"Total Precip (mm)\"] = total_precip\n",
        "    if \"Spd of Max Gust (km/h)\" in base_input:\n",
        "        base_input[\"Spd of Max Gust (km/h)\"] = wind_gust\n",
        "\n",
        "    # Lot indicator â€“ one-hot\n",
        "    if selected_lot_feature is not None and selected_lot_feature in base_input:\n",
        "        base_input[selected_lot_feature] = 1\n",
        "\n",
        "    # Vector in the exact training feature order\n",
        "    x_vec = np.array([base_input[f] for f in FEATURES]).reshape(1, -1)\n",
        "    x_scaled = scaler.transform(x_vec)\n",
        "\n",
        "    if st.button(\"ðŸ”® Predict for this scenario\"):\n",
        "        # Current-hour predictions\n",
        "        occ_pred = best_xgb_reg.predict(x_scaled)[0]\n",
        "        full_prob = best_xgb_cls.predict_proba(x_scaled)[0, 1]\n",
        "\n",
        "        st.subheader(\"Step 3 â€“ Results for Selected Hour\")\n",
        "\n",
        "        col_res1, col_res2 = st.columns(2)\n",
        "        with col_res1:\n",
        "            st.metric(\"Predicted occupancy (model units)\",\n",
        "                      f\"{occ_pred:.2f}\")\n",
        "        with col_res2:\n",
        "            st.metric(\"Probability lot is near full\",\n",
        "                      f\"{full_prob:.1%}\")\n",
        "\n",
        "        if full_prob > 0.7:\n",
        "            st.warning(\n",
        "                \"âš ï¸ High risk this lot will be full. Consider redirecting drivers \"\n",
        "                \"to other parking areas or adjusting signage.\"\n",
        "            )\n",
        "        elif full_prob > 0.4:\n",
        "            st.info(\n",
        "                \"Moderate risk of heavy usage. Monitoring and dynamic guidance \"\n",
        "                \"could be useful.\"\n",
        "            )\n",
        "        else:\n",
        "            st.success(\n",
        "                \"Low risk of the lot being at full capacity for this hour.\"\n",
        "            )\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# PAGE 3 â€“ LOT STATUS OVERVIEW (ALL LOTS AT ONCE)\n",
        "# ---------------------------------------------------\n",
        "if page == \"Lot Status Overview\":\n",
        "    st.title(\"ðŸ“Š Lot Status Overview â€“ Which Lots Are Likely Full?\")\n",
        "\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        This page shows, for a selected hour and conditions, the predicted:\n",
        "\n",
        "        - **Occupancy** for each parking lot\n",
        "        - **Probability that the lot is near full**\n",
        "        - Simple status: ðŸŸ¥ High risk, ðŸŸ§ Busy, ðŸŸ© Comfortable\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    lot_features = [f for f in FEATURES if f.startswith(\"Unit_\")]\n",
        "    lot_display_names = [lf.replace(\"Unit_\", \"\").replace(\"_\", \" \") for lf in lot_features]\n",
        "\n",
        "    # sort lots alphabetically so numbers are in sequence\n",
        "    if lot_features:\n",
        "        lot_pairs = sorted(zip(lot_features, lot_display_names), key=lambda x: x[1])\n",
        "        lot_features, lot_display_names = zip(*lot_pairs)\n",
        "        lot_features = list(lot_features)\n",
        "        lot_display_names = list(lot_display_names)\n",
        "\n",
        "    if not lot_features:\n",
        "        st.error(\n",
        "            \"No parking-lot indicator features (starting with 'Unit_') were \"\n",
        "            \"found in FEATURES. This view needs those to work.\"\n",
        "        )\n",
        "    else:\n",
        "        st.subheader(\"Step 1 â€“ Choose time & weather\")\n",
        "\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            month = st.slider(\"Month (1 = Jan, 12 = Dec)\", 1, 12, 7)\n",
        "            day_of_week = st.slider(\"Day of Week (0 = Monday, 6 = Sunday)\", 0, 6, 5)\n",
        "            hour = st.slider(\"Hour of Day\", 0, 23, 14)\n",
        "\n",
        "        with col2:\n",
        "            max_temp = st.slider(\"Max Temperature (Â°C)\", -20.0, 40.0, 22.0)\n",
        "            total_precip = st.slider(\"Total Precipitation (mm)\", 0.0, 30.0, 0.5)\n",
        "            wind_gust = st.slider(\"Speed of Max Gust (km/h)\", 0.0, 100.0, 12.0)\n",
        "\n",
        "        is_weekend = 1 if day_of_week in [5, 6] else 0\n",
        "\n",
        "        st.caption(\n",
        "            \"Lag features (previous-hour occupancy, rolling averages) are set to 0 \"\n",
        "            \"for this overview. In a real system they would come from live feeds.\"\n",
        "        )\n",
        "\n",
        "        if st.button(\"Compute lot status\"):\n",
        "            rows = []\n",
        "\n",
        "            # Base feature template\n",
        "            base_input = {f: 0 for f in FEATURES}\n",
        "\n",
        "            # Common time & weather fields\n",
        "            if \"Month\" in base_input:\n",
        "                base_input[\"Month\"] = month\n",
        "            if \"DayOfWeek\" in base_input:\n",
        "                base_input[\"DayOfWeek\"] = day_of_week\n",
        "            if \"Hour\" in base_input:\n",
        "                base_input[\"Hour\"] = hour\n",
        "            if \"IsWeekend\" in base_input:\n",
        "                base_input[\"IsWeekend\"] = is_weekend\n",
        "            if \"Max Temp (Â°C)\" in base_input:\n",
        "                base_input[\"Max Temp (Â°C)\"] = max_temp\n",
        "            if \"Total Precip (mm)\" in base_input:\n",
        "                base_input[\"Total Precip (mm)\"] = total_precip\n",
        "            if \"Spd of Max Gust (km/h)\" in base_input:\n",
        "                base_input[\"Spd of Max Gust (km/h)\"] = wind_gust\n",
        "\n",
        "            # Loop over each lot, one-hot encode, and predict\n",
        "            for lot_feat, lot_name in zip(lot_features, lot_display_names):\n",
        "                lot_input = base_input.copy()\n",
        "                if lot_feat in lot_input:\n",
        "                    lot_input[lot_feat] = 1\n",
        "\n",
        "                x_vec = np.array([lot_input[f] for f in FEATURES]).reshape(1, -1)\n",
        "                x_scaled = scaler.transform(x_vec)\n",
        "\n",
        "                occ_pred = best_xgb_reg.predict(x_scaled)[0]\n",
        "                full_prob = best_xgb_cls.predict_proba(x_scaled)[0, 1]\n",
        "\n",
        "                if full_prob > 0.7:\n",
        "                    status = \"ðŸŸ¥ High risk full\"\n",
        "                elif full_prob > 0.4:\n",
        "                    status = \"ðŸŸ§ Busy\"\n",
        "                else:\n",
        "                    status = \"ðŸŸ© Comfortable\"\n",
        "\n",
        "                rows.append(\n",
        "                    {\n",
        "                        \"Lot\": lot_name,\n",
        "                        \"Predicted occupancy\": occ_pred,\n",
        "                        \"Probability full\": full_prob,\n",
        "                        \"Status\": status,\n",
        "                    }\n",
        "                )\n",
        "\n",
        "            df = pd.DataFrame(rows)\n",
        "            # sort by lot name so numbers are in sequence\n",
        "            df = df.sort_values(\"Lot\")\n",
        "\n",
        "            # ---------- nice colour styling ----------\n",
        "            def lot_status_row_style(row):\n",
        "                if \"High risk\" in row[\"Status\"]:\n",
        "                    return [\"background-color: #ffe5e5\"] * len(row)  # light red\n",
        "                elif \"Busy\" in row[\"Status\"]:\n",
        "                    return [\"background-color: #fff4e0\"] * len(row)  # light orange\n",
        "                else:\n",
        "                    return [\"background-color: #e9f7ef\"] * len(row)  # light green\n",
        "\n",
        "            styled_df = (\n",
        "                df.style\n",
        "                .format(\n",
        "                    {\"Predicted occupancy\": \"{:.2f}\",\n",
        "                     \"Probability full\": \"{:.1%}\"}\n",
        "                )\n",
        "                .apply(lot_status_row_style, axis=1)\n",
        "            )\n",
        "\n",
        "            st.subheader(\"Step 2 â€“ Lot status for selected hour\")\n",
        "            st.dataframe(\n",
        "                styled_df,\n",
        "                use_container_width=True,\n",
        "            )\n",
        "\n",
        "            st.caption(\n",
        "                \"Lots are shown in numeric order (BANFF02, BANFF03, â€¦). \"\n",
        "                \"Row colour shows risk level: red = high risk, orange = busy, \"\n",
        "                \"green = comfortable.\"\n",
        "            )\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# PAGE 4 â€“ XAI (EXPLAINABLE AI)\n",
        "# ---------------------------------------------------\n",
        "if page == \"XAI â€“ Explainable AI\":\n",
        "    st.title(\"ðŸ” Explainable AI â€“ Understanding the Models\")\n",
        "\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        This page explains **why** the models make their predictions,\n",
        "        using Explainable AI tools:\n",
        "\n",
        "        - **SHAP summary plot**: which features contribute most to predictions\n",
        "        - **SHAP bar plot**: overall feature importance\n",
        "        - **Partial Dependence Plots (PDPs)**: effect of one feature at a time\n",
        "        - **Residual plot**: how close predictions are to the true values\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # ---------- SHAP EXPLANATIONS FOR REGRESSION ----------\n",
        "    st.subheader(\"SHAP Summary â€“ Regression Model (Occupancy)\")\n",
        "\n",
        "    try:\n",
        "        explainer_reg = shap.TreeExplainer(best_xgb_reg)\n",
        "        shap_values_reg = explainer_reg.shap_values(X_test_scaled)\n",
        "\n",
        "        # Summary dot plot\n",
        "        fig1, ax1 = plt.subplots()\n",
        "        shap.summary_plot(\n",
        "            shap_values_reg,\n",
        "            X_test_scaled,\n",
        "            feature_names=FEATURES,\n",
        "            show=False\n",
        "        )\n",
        "        st.pyplot(fig1)\n",
        "        st.caption(\n",
        "            \"Each point represents a sample. Colour shows feature value, and position \"\n",
        "            \"shows how much that feature pushed the prediction up or down.\"\n",
        "        )\n",
        "\n",
        "        # Summary bar plot\n",
        "        st.subheader(\"SHAP Feature Importance â€“ Regression\")\n",
        "        fig2, ax2 = plt.subplots()\n",
        "        shap.summary_plot(\n",
        "            shap_values_reg,\n",
        "            X_test_scaled,\n",
        "            feature_names=FEATURES,\n",
        "            plot_type=\"bar\",\n",
        "            show=False\n",
        "        )\n",
        "        st.pyplot(fig2)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Could not generate SHAP plots: {e}\")\n",
        "\n",
        "    # ---------- PARTIAL DEPENDENCE PLOTS ----------\n",
        "    st.subheader(\"Partial Dependence â€“ Key Features\")\n",
        "\n",
        "    pd_feature_names = []\n",
        "    for name in [\"Max Temp (Â°C)\", \"Month\", \"Hour\"]:\n",
        "        if name in FEATURES:\n",
        "            pd_feature_names.append(name)\n",
        "\n",
        "    if len(pd_feature_names) > 0:\n",
        "        feature_indices = [FEATURES.index(f) for f in pd_feature_names]\n",
        "        fig3, ax3 = plt.subplots(figsize=(10, 4))\n",
        "        PartialDependenceDisplay.from_estimator(\n",
        "            best_xgb_reg,\n",
        "            X_test_scaled,\n",
        "            feature_indices,\n",
        "            feature_names=FEATURES,\n",
        "            ax=ax3\n",
        "        )\n",
        "        st.pyplot(fig3)\n",
        "        st.caption(\n",
        "            \"Partial dependence shows the average effect of each feature on predicted \"\n",
        "            \"occupancy while holding other features constant.\"\n",
        "        )\n",
        "    else:\n",
        "        st.info(\n",
        "            \"Could not find the configured PDP features ('Max Temp (Â°C)', 'Month', 'Hour') \"\n",
        "            \"in the FEATURES list. You may need to adjust the feature names.\"\n",
        "        )\n",
        "\n",
        "    # ---------- RESIDUAL ANALYSIS ----------\n",
        "    st.subheader(\"Residual Plot â€“ Regression Model\")\n",
        "\n",
        "    try:\n",
        "        y_pred = best_xgb_reg.predict(X_test_scaled)\n",
        "        residuals = y_reg_test - y_pred\n",
        "\n",
        "        fig4, ax4 = plt.subplots()\n",
        "        ax4.scatter(y_pred, residuals, alpha=0.3)\n",
        "        ax4.axhline(0, color=\"red\", linestyle=\"--\")\n",
        "        ax4.set_xlabel(\"Predicted Occupancy\")\n",
        "        ax4.set_ylabel(\"Residual (Actual - Predicted)\")\n",
        "        st.pyplot(fig4)\n",
        "        st.caption(\n",
        "            \"Residuals scattered symmetrically around zero suggest that the model \"\n",
        "            \"captures the main patterns without strong systematic bias.\"\n",
        "        )\n",
        "    except Exception as e:\n",
        "        st.error(f\"Could not compute residuals: {e}\")\n",
        "\n",
        "# ---------------------------------------------------\n",
        "# PAGE 5 â€“ CHAT ASSISTANT (RAG)\n",
        "# ---------------------------------------------------\n",
        "if page == \"ðŸ’¬ Chat Assistant (RAG)\":\n",
        "    st.title(\"ðŸ’¬ Banff Parking Chat Assistant (RAG)\")\n",
        "\n",
        "    st.markdown(\n",
        "        \"\"\"\n",
        "        Ask questions about parking patterns, busy times, or model behaviour.\n",
        "\n",
        "        This chatbot uses **RAG (Retrieval-Augmented Generation)**:\n",
        "        1. It first retrieves relevant lines from your `banff_knowledge.txt` file\n",
        "        2. Then it uses an OpenAI model to answer, grounded in that context\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Initialize chat history\n",
        "    if \"rag_chat_history\" not in st.session_state:\n",
        "        st.session_state.rag_chat_history = []\n",
        "\n",
        "    # Show previous messages\n",
        "    for msg in st.session_state.rag_chat_history:\n",
        "        with st.chat_message(msg[\"role\"]):\n",
        "            st.markdown(msg[\"content\"])\n",
        "\n",
        "    # User input\n",
        "    user_input = st.chat_input(\"Ask something about Banff parking...\")\n",
        "\n",
        "    if user_input:\n",
        "        # Add user message to history\n",
        "        st.session_state.rag_chat_history.append(\n",
        "            {\"role\": \"user\", \"content\": user_input}\n",
        "        )\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(user_input)\n",
        "\n",
        "        # Assistant response\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            with st.spinner(\"Thinking with project context...\"):\n",
        "                answer = generate_chat_answer(\n",
        "                    user_input,\n",
        "                    st.session_state.rag_chat_history,\n",
        "                )\n",
        "                st.markdown(answer)\n",
        "\n",
        "        st.session_state.rag_chat_history.append(\n",
        "            {\"role\": \"assistant\", \"content\": answer}\n",
        "        )\n",
        "\n",
        "    st.caption(\n",
        "        \"Tip: edit `banff_knowledge.txt` in your repo to control what the chatbot knows \"\n",
        "        \"about your EDA, feature engineering, and model findings.\"\n",
        "    )"
      ]
    }
  ]
}